{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MZJN0FkKGAP7hxPLB2Fy_G7lOeyJNXJg",
      "authorship_tag": "ABX9TyPV5xMtbUA+0WisBuDkdwHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clara-lan/Capstone/blob/SVM_YOLO_Object/CapstoneSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use SVM to detect empty space and pre-process images"
      ],
      "metadata": {
        "id": "J93ZoQDqaIYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step1: Import system and dependancies"
      ],
      "metadata": {
        "id": "Nwzzdw3yaTjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LtTklnf1hEW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog"
      ],
      "metadata": {
        "id": "Qz5dhKUwauId"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset from Roboflow"
      ],
      "metadata": {
        "id": "876UEB-fahHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import feature"
      ],
      "metadata": {
        "id": "DGizEmtn98UI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL"
      ],
      "metadata": {
        "id": "JJOwwmQWCC9y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.fixes import sklearn\n",
        "import tensorflow.python.platform\n",
        "from tensorflow.python.platform import gfile"
      ],
      "metadata": {
        "id": "IpgNXMqw-4Hy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Read method1: Load roboflow dataset from Roboflow\"\"\"\n",
        "rf = Roboflow(api_key=\"cKIuGvQRsLbBvFgxNztc\")\n",
        "project = rf.workspace(\"myworkspace-nfnwm\").project(\"projectdb\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EN_dFXHkgpV",
        "outputId": "8d5df847-8a5e-4c57-940a-2fda7f9c1885"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = project.version(2).download(\"tfrecord\")"
      ],
      "metadata": {
        "id": "cr4CxtiolaFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Download dataset in YOLOv7 object\"\"\"\n",
        "!pwd\n",
        "yolo_dataset = project.version(2).download(\"yolov7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D28vQ2GLkooD",
        "outputId": "9fa86d44-74af-485d-a364-14d5f54b6ba6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading Dataset Version Zip in ProjectDB-2 to yolov7pytorch: 100% [41723011 / 41723011] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to ProjectDB-2 in yolov7pytorch:: 100%|██████████| 1144/1144 [00:00<00:00, 1168.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Read images from tf record\"\"\"\n",
        "def extract_images(path,mode):\n",
        "  \"\"\"\n",
        "    Function: extract_images\n",
        "    Input: path - valid image path in tf record\n",
        "           mode - 1 for training, 2 for test\n",
        "    Output: image dict, {key: {image, label}}, key is index\n",
        "    Description: This function extract images and labels from tfrecord, maps them to corresponding index\n",
        "  \"\"\"\n",
        "  images = {}\n",
        "  # Create a description of the features.\n",
        "  features = {\n",
        "      \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"image/height\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"image/object/bbox/xmax\": tf.io.VarLenFeature(tf.float32),\n",
        "      \"image/object/bbox/xmin\": tf.io.VarLenFeature(tf.float32),\n",
        "      \"image/object/bbox/ymax\": tf.io.VarLenFeature(tf.float32),\n",
        "      \"image/object/bbox/ymin\": tf.io.VarLenFeature(tf.float32),\n",
        "      \"image/object/class/label\": tf.io.VarLenFeature(tf.int64),\n",
        "      \"image/object/class/text\": tf.io.VarLenFeature(tf.string),\n",
        "      \"image/width\": tf.io.FixedLenFeature([], tf.int64),\n",
        "  }\n",
        "  size = 0\n",
        "  idx = 0\n",
        "  if mode == 1:\n",
        "    size = 400\n",
        "  elif mode == 2:\n",
        "    size = 100\n",
        "  train_dataset = tf.data.TFRecordDataset(path)\n",
        "  for raw_record in train_dataset.take(size):\n",
        "    sample = tf.io.parse_single_example(raw_record, features)\n",
        "    image = tf.image.decode_image(sample['image/encoded'], dtype=tf.float32) \n",
        "    label = sample['image/object/class/label']\n",
        "    images[idx] = [image, label]\n",
        "    idx+=1\n",
        "  return images\n",
        "# path =  '/content/Capstone-3/train/empty-shelf-space.tfrecord'\n",
        "# extract_images(path, 1)"
      ],
      "metadata": {
        "id": "lOfRNPtyQi9u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Read images from YOLOv7\"\"\"\n",
        "\n",
        "def extract_images_from_yolov7(path,mode):\n",
        "  \"\"\"\n",
        "    Function: extract_images\n",
        "    Input: path - valid image path in tf record\n",
        "           mode - 1 for training, 2 for test\n",
        "    Output: image dict, {key: {image, label}}, key is index, image is the images name, label is the name of label file\n",
        "  \"\"\"\n",
        "  image_labels_dict = {}\n",
        "  images_path = path+\"/images\"\n",
        "  labels_path = path+'/labels'\n",
        "  images = [f for f in os.listdir(images_path)]\n",
        "  labels = [f for f in os.listdir(labels_path)]\n",
        "  images.sort()\n",
        "  labels.sort()\n",
        "  for i in range(len(images)):\n",
        "    image_labels_dict[i] = [images[i], labels[i]]\n",
        "    # print(images[i])\n",
        "    # # print(\"tuple: \",images[i], \"====tuple:\", labels[i])\n",
        "    # return\n",
        "\n",
        "  return image_labels_dict\n",
        "\n",
        "# extract_images_from_yolov7('/content/ProjectDB-2/test',1)"
      ],
      "metadata": {
        "id": "AeInO3ark6ul"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step2: Preprocess data"
      ],
      "metadata": {
        "id": "HI6gpfcDapC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Convert Tensor to image\n",
        "  Show Image\n",
        "\"\"\"\n",
        "def show_image_from_tensor(tensor):\n",
        "    tensor = tensor*255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "        img_arr = PIL.Image.fromarray(tensor)\n",
        "        plt.imshow(img_arr, interpolation='nearest')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "mGTD6oXq-Mok"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_dataset = tf.data.TFRecordDataset('/content/Empty-shelf-detection-15/test/Empty-space.tfrecord')\n",
        "# valid_dataset = tf.data.TFRecordDataset('/content/Empty-shelf-detection-15/valid/Empty-space.tfrecord')\n",
        "train_labels = '/content/ProjectDB-2/train/empty-shelf-space_label_map.pbtxt'\n",
        "# valid_labels = '/content/Empty-shelf-detection-15/valid/Empty-space_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "1CpXZtaDPG9G"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step3: Train SVM\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GeQM7_yAZniY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def datagen(mode):\n",
        "    \"\"\"\n",
        "    Function: datagen \n",
        "    \n",
        "    Input: \n",
        "        mode - 1 denotes train data ; 2 denotes test data\n",
        "    \n",
        "    Output: Train/Test data and labels depending on mode value\n",
        "    \n",
        "    Description: This function computes HOG features for each image in the Dataset/train or Dataset/test folder, assigns label to the descriptor vector of the image and returns the final train/test data and labels matrices used for feeding the SVM in training phase or predicting the label of test data.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    ind = 0\n",
        "    if mode == 1:\n",
        "        path = '/content/ProjectDB-2/train/empty-shelf-space.tfrecord'\n",
        "    elif mode == 2:\n",
        "        path = '/content/ProjectDB-2/valid/empty-shelf-space.tfrecord'\n",
        "    # read image\n",
        "    images = extract_images(path, mode)\n",
        "    for key in images.keys():\n",
        "        # compute HOG features\n",
        "        img, label = images[key][0], images[key][1]\n",
        "        # print(type(img))\n",
        "        des, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n",
        "        # print(\"des:\",des)\n",
        "        # print(hog_image)\n",
        "        # print(\"des: \", des)\n",
        "        \"\"\"Read labels\"\"\"\n",
        "        # cv2_imshow(hog_image)\n",
        "        # append descriptor and label to train/test data, labels\n",
        "        label = tf.sparse.to_dense(label).numpy().tolist()\n",
        "        if(len(label) > 0):\n",
        "          X.append(des)\n",
        "          y.append(label)\n",
        "    return X, y\n",
        "# datagen(2)\n",
        "# x,y = datagen(1)\n",
        "# print(\"y: \", y)\n"
      ],
      "metadata": {
        "id": "1iD7Wrf-ZuPp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\"\"\"Read labels from .txt file\"\"\"\n",
        "def read_labels(filename):\n",
        "  labels = [x.split(' ') for x in open(filename).readlines()]\n",
        "  for label in labels:\n",
        "    label[-1].rstrip()\n",
        "  return labels\n"
      ],
      "metadata": {
        "id": "Ceie-MOraGDo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from random import randrange\n",
        "def datagen_yolov7(mode):\n",
        "    \"\"\"\n",
        "    Function: datagen_yolov7 \n",
        "    \n",
        "    Input: \n",
        "        mode - 1 denotes train data ; 2 denotes test data\n",
        "    \n",
        "    Output: Train/Test data and labels depending on mode value\n",
        "    \n",
        "    Description: This function computes HOG features for each image in the Dataset/train or Dataset/test folder, assigns label to the descriptor vector of the image and returns the final train/test data and labels matrices used for feeding the SVM in training phase or predicting the label of test data.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    ind = 0\n",
        "    if mode == 1:\n",
        "        path = '/content/ProjectDB-2/train'\n",
        "    elif mode == 2:\n",
        "        path = '/content/ProjectDB-2/valid'\n",
        "    # read image\n",
        "    image_labels_dict = extract_images_from_yolov7(path, mode)\n",
        "    for key in image_labels_dict.keys():\n",
        "        # compute HOG features\n",
        "        img, label = image_labels_dict[key][0], image_labels_dict[key][1]\n",
        "        # print(img)\n",
        "        image = cv2.imread(path+'/images/'+img)\n",
        "        # cv2_imshow(image)\n",
        "        # return\n",
        "        img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img,(128,128))\n",
        "\n",
        "        # print(type(img))\n",
        "        des, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n",
        "        # print(\"des:\",des)\n",
        "        # print(hog_image)\n",
        "        # print(\"des: \", des)\n",
        "        \"\"\"Read labels\"\"\"\n",
        "        # cv2_imshow(hog_image)\n",
        "        # append descriptor and label to train/test data, labels\n",
        "        X.append(des)\n",
        "        # print(des)\n",
        "        label = read_labels(path+'/labels/'+label)\n",
        "        #store only one label, random get label by index\n",
        "        y.append(label[randrange(len(label))])\n",
        "    return X, y\n",
        "\n",
        "# datagen_yolov7(2)"
      ],
      "metadata": {
        "id": "TybcVsqxqhSB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_svm():\n",
        "#     # list of training and test files\n",
        "#     # call 'datagen' function to get training and testing data & labels\n",
        "#     mlb = MultiLabelBinarizer()\n",
        "#     Xtrain, ytrain = datagen(1)\n",
        "#     Xtest, ytest = datagen(2)\n",
        "\n",
        "#     # print(\"ytrain: \", ytrain)\n",
        "#     # convert matrices to numpy array for fast computation\n",
        "#     Xtrain_arr = np.array(Xtrain)\n",
        "#     # convert labels to 1d array to enabel sklearn\n",
        "#     ytrain = [item[0] for item in ytrain]\n",
        "#     # print(\"x: \", len(Xtrain))\n",
        "#     # print(\"ytrain: \", ytrain)\n",
        "#     Xtest_arr = np.array(Xtest)\n",
        "#     ytest = [item[0] for item in ytest]\n",
        "\n",
        "#     # training phase: SVM , fit model to training data ------------------------------\n",
        "#     clf = svm.SVC(kernel = 'linear')\n",
        "#     clf.fit(Xtrain_arr, ytrain)\n",
        "#     # predict labels for test data\n",
        "#     ypred = clf.predict(Xtest_arr)\n",
        "    \n",
        "#     # compute accuracy\n",
        "#     accuracy = accuracy_score(ytest, ypred) * 100\n",
        "#     print(\"\\nAccuracy: %.2f\" % accuracy + \"%\")\n",
        "# start_time = time.time()\n",
        "# train_svm()\n",
        "# print('Execution time: %.2f' % (time.time() - start_time) + ' seconds\\n')"
      ],
      "metadata": {
        "id": "0VvYlhGxnFrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm_with_yolo_object():\n",
        "    # list of training and test files\n",
        "    # call 'datagen' function to get training and testing data & labels\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    Xtrain, ytrain = datagen_yolov7(1)\n",
        "    Xtest, ytest = datagen_yolov7(2)\n",
        "\n",
        "    # print(\"ytrain: \", ytrain)\n",
        "    # convert matrices to numpy array for fast computation\n",
        "    Xtrain_arr = np.array(Xtrain)\n",
        "    # convert labels to 1d array to enabel sklearn\n",
        "    ytrain = [item[0] for item in ytrain]\n",
        "    # print(\"x: \", len(Xtrain))\n",
        "    # print(\"ytrain: \", ytrain)\n",
        "    \n",
        "\n",
        "    Xtest_arr = np.array(Xtest)\n",
        "    ytest = [item[0] for item in ytest]\n",
        "\n",
        "    # training phase: SVM , fit model to training data ------------------------------\n",
        "    clf = svm.SVC(kernel = 'linear')\n",
        "    clf.fit(Xtrain_arr, ytrain)\n",
        "    # predict labels for test data\n",
        "    ypred = clf.predict(Xtest_arr)\n",
        "    \n",
        "    # compute accuracy\n",
        "    accuracy = accuracy_score(ytest, ypred) * 100\n",
        "    print(\"\\nAccuracy: %.2f\" % accuracy + \"%\")\n",
        "\n",
        "start_time = time.time()\n",
        "train_svm_with_yolo_object()\n",
        "print('Execution time: %.2f' % (time.time() - start_time) + ' seconds\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpod4cUYhTdn",
        "outputId": "ba5b8284-326c-4822-8293-8dcedfa334ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 51.79%\n",
            "Execution time: 7.44 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train with YOLO\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "t01hZ95f3wcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/WongKinYiu/yolov7\n",
        "# %cd yolov7\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "u8x0qzA9Pdoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGW7gP6yE_fl",
        "outputId": "e985e71d-a286-48e4-eec5-b0a1fa1c7597"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 998, done.\u001b[K\n",
            "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n",
            "Receiving objects: 100% (998/998), 69.77 MiB | 15.16 MiB/s, done.\n",
            "Resolving deltas: 100% (467/467), done.\n",
            "/content/yolov7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.28.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.13.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 34)) (7.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (5.4.8)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4.21.3->-r requirements.txt (line 14)) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.50.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.35.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.5)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.1 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download COCO starting checkpoint\n",
        "%cd /content/yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YarX9wvDFzB3",
        "outputId": "6a3fbeb1-df98-4c96-f736-aa120faa3825"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "--2022-10-29 20:19:08--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221029%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221029T201909Z&X-Amz-Expires=300&X-Amz-Signature=a7e8768e6e5e9f0ecb71b309012efed3ea9a3d7c7234c684f2850dd8d175bc65&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-10-29 20:19:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221029%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221029T201909Z&X-Amz-Expires=300&X-Amz-Signature=a7e8768e6e5e9f0ecb71b309012efed3ea9a3d7c7234c684f2850dd8d175bc65&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7_training.pt’\n",
            "\n",
            "yolov7_training.pt  100%[===================>]  72.12M  11.1MB/s    in 9.5s    \n",
            "\n",
            "2022-10-29 20:19:19 (7.61 MB/s) - ‘yolov7_training.pt’ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "7hYCeteLWEkM",
        "outputId": "0c21475e-bd39-404b-af78-2ea07ba9c67b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:15:21tcmalloc: large alloc 1147494400 bytes == 0x394b8000 @  0x7fc25a574615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.4 MB/s eta 0:12:04tcmalloc: large alloc 1434370048 bytes == 0x7db0e000 @  0x7fc25a574615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:49tcmalloc: large alloc 1792966656 bytes == 0x2940000 @  0x7fc25a574615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.3 MB/s eta 0:04:33tcmalloc: large alloc 2241208320 bytes == 0x6d728000 @  0x7fc25a574615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf308a000 @  0x7fc25a5731e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x1e100e000 @  0x7fc25a574615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.1 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 100.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 35.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB1BO7MEXtFl",
        "outputId": "38ce6c77-f46c-464a-fddb-6c4b9eee0d2d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "NANvpYaQYaGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K05SarInXdUX",
        "outputId": "cbe0e573-5e4d-4a5e-f187-83ebb4db81e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this cell to begin training\n",
        "%cd /content/yolov7\n",
        "\"\"\"Download dataset in YOLOv7 object\"\"\"\n",
        "yolo_dataset = project.version(2).download(\"yolov7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dx78NluGAN1",
        "outputId": "11f24e80-379a-4f99-cbbc-350eb3272951"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Downloading Dataset Version Zip in ProjectDB-2 to yolov7pytorch: 100% [41723011 / 41723011] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to ProjectDB-2 in yolov7pytorch:: 100%|██████████| 1144/1144 [00:00<00:00, 1323.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py [-h] [--weights WEIGHTS] [--cfg CFG] [--data DATA] [--hyp HYP]\n",
            "                [--epochs EPOCHS] [--batch-size BATCH_SIZE]\n",
            "                [--img-size IMG_SIZE [IMG_SIZE ...]] [--rect]\n",
            "                [--resume [RESUME]] [--nosave] [--notest] [--noautoanchor]\n",
            "                [--evolve] [--bucket BUCKET] [--cache-images]\n",
            "                [--image-weights] [--device DEVICE] [--multi-scale]\n",
            "                [--single-cls] [--adam] [--sync-bn] [--local_rank LOCAL_RANK]\n",
            "                [--workers WORKERS] [--project PROJECT] [--entity ENTITY]\n",
            "                [--name NAME] [--exist-ok] [--quad] [--linear-lr]\n",
            "                [--label-smoothing LABEL_SMOOTHING] [--upload_dataset]\n",
            "                [--bbox_interval BBOX_INTERVAL] [--save_period SAVE_PERIOD]\n",
            "                [--artifact_alias ARTIFACT_ALIAS]\n",
            "                [--freeze FREEZE [FREEZE ...]] [--v5-metric]\n",
            "train.py: error: unrecognized arguments: yolov7_training.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python train.py --batch 16 --epochs 55 --data /content/yolov7/ProjectDB-2/data.yaml --weights 'yolov7_training.pt' --device 0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1Sz7KoOcE3S",
        "outputId": "488cb404-eef7-450f-971f-ded13e1461b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.9.0+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='/content/yolov7/ProjectDB-2/data.yaml', device='0', entity=None, epochs=55, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp3', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     39550  models.yolo.IDetect                     [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 415 layers, 37201950 parameters, 37201950 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 557/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'ProjectDB-2/train/labels' images and labels... 395 found, 0 missing, 0 empty, 0 corrupted: 100% 395/395 [00:00<00:00, 2581.75it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ProjectDB-2/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'ProjectDB-2/valid/labels' images and labels... 112 found, 0 missing, 0 empty, 0 corrupted: 100% 112/112 [00:00<00:00, 871.52it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ProjectDB-2/valid/labels.cache\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.70, Best Possible Recall (BPR) = 0.9926\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp3\n",
            "Starting training for 55 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/54      7.4G   0.07661   0.02057   0.01664    0.1138        45       640: 100% 25/25 [00:52<00:00,  2.09s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:15<00:00,  3.80s/it]\n",
            "                 all         112         511      0.0105      0.0975     0.00445     0.00073\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/54     11.6G   0.07249   0.01839   0.01536    0.1062        87       640: 100% 25/25 [00:34<00:00,  1.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.21it/s]\n",
            "                 all         112         511      0.0227       0.098      0.0116     0.00205\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/54       13G   0.06759   0.01844   0.01373   0.09976        49       640: 100% 25/25 [00:33<00:00,  1.32s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.10it/s]\n",
            "                 all         112         511      0.0258       0.106      0.0143     0.00285\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/54       13G   0.06385   0.01774   0.01293   0.09452        62       640: 100% 25/25 [00:31<00:00,  1.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.41it/s]\n",
            "                 all         112         511      0.0398       0.116      0.0241     0.00504\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/54       13G   0.06108   0.01825   0.01204   0.09137        49       640: 100% 25/25 [00:30<00:00,  1.22s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.18it/s]\n",
            "                 all         112         511       0.548      0.0623      0.0241     0.00562\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/54       13G   0.05741   0.02014   0.01104   0.08858        80       640: 100% 25/25 [00:30<00:00,  1.23s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.38it/s]\n",
            "                 all         112         511       0.558       0.163      0.0457      0.0117\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/54       13G   0.05542   0.01939   0.01089    0.0857        85       640: 100% 25/25 [00:33<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.19it/s]\n",
            "                 all         112         511      0.0353       0.387      0.0354     0.00783\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/54       13G   0.05423   0.01912   0.01084    0.0842        71       640: 100% 25/25 [00:32<00:00,  1.30s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.22it/s]\n",
            "                 all         112         511       0.101       0.202      0.0798       0.028\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/54       13G   0.05275   0.01977   0.01031   0.08282       124       640: 100% 25/25 [00:32<00:00,  1.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.25it/s]\n",
            "                 all         112         511       0.593       0.223      0.0773      0.0278\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/54       13G   0.05197   0.01801    0.0105   0.08048        50       640: 100% 25/25 [00:32<00:00,  1.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.26it/s]\n",
            "                 all         112         511       0.605       0.211      0.0861      0.0314\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/54       13G   0.04954   0.01927   0.01032   0.07914       109       640: 100% 25/25 [00:36<00:00,  1.45s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.49it/s]\n",
            "                 all         112         511       0.602        0.23      0.0957      0.0399\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/54       13G   0.04781   0.01967   0.01074   0.07823        43       640: 100% 25/25 [00:36<00:00,  1.48s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.46it/s]\n",
            "                 all         112         511       0.615       0.234       0.114      0.0463\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/54       13G   0.04556   0.01904   0.01105   0.07565        39       640: 100% 25/25 [00:32<00:00,  1.29s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.22it/s]\n",
            "                 all         112         511       0.621        0.22        0.11      0.0456\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/54       13G   0.04675   0.01847   0.01076   0.07599        73       640: 100% 25/25 [00:35<00:00,  1.43s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.32it/s]\n",
            "                 all         112         511       0.124       0.546       0.145      0.0611\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/54       13G   0.04426   0.01917  0.009976   0.07341        43       640: 100% 25/25 [00:31<00:00,  1.27s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.23it/s]\n",
            "                 all         112         511       0.206       0.535       0.203      0.0848\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/54       13G   0.04435   0.01933   0.00897   0.07265        67       640: 100% 25/25 [00:32<00:00,  1.30s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "                 all         112         511       0.304       0.519       0.248       0.108\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/54       13G   0.04356   0.01748    0.0103   0.07134        63       640: 100% 25/25 [00:31<00:00,  1.27s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.27it/s]\n",
            "                 all         112         511       0.337       0.482       0.289        0.13\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/54       13G   0.04246   0.01706  0.009901   0.06942        68       640: 100% 25/25 [00:31<00:00,  1.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.26it/s]\n",
            "                 all         112         511       0.258       0.518       0.254       0.118\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/54       13G   0.04167   0.01953  0.009283   0.07048        92       640: 100% 25/25 [00:35<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.28it/s]\n",
            "                 all         112         511       0.323       0.563       0.309        0.14\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/54       13G   0.04115   0.01846  0.008974   0.06858        65       640: 100% 25/25 [00:30<00:00,  1.22s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "                 all         112         511        0.34       0.593       0.347       0.145\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/54       13G   0.04593   0.01741  0.008549   0.07189        85       640: 100% 25/25 [00:32<00:00,  1.31s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.30it/s]\n",
            "                 all         112         511       0.343       0.569       0.341        0.14\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/54       13G   0.04411   0.01751  0.008665   0.07029        64       640: 100% 25/25 [00:31<00:00,  1.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.32it/s]\n",
            "                 all         112         511        0.36       0.493       0.322       0.129\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/54       13G   0.04218    0.0179  0.008908   0.06899        49       640: 100% 25/25 [00:38<00:00,  1.54s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.29it/s]\n",
            "                 all         112         511       0.358        0.61       0.359       0.159\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/54       13G   0.04218   0.01836  0.008646   0.06918        78       640: 100% 25/25 [00:29<00:00,  1.18s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.30it/s]\n",
            "                 all         112         511       0.332       0.558       0.325       0.142\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/54       13G   0.04094   0.01804  0.009208   0.06819        82       640: 100% 25/25 [00:32<00:00,  1.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "                 all         112         511       0.354       0.551       0.354       0.163\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/54       13G   0.03868   0.01793  0.008097   0.06471        68       640: 100% 25/25 [00:31<00:00,  1.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.23it/s]\n",
            "                 all         112         511        0.37       0.561       0.359        0.16\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/54       13G   0.03928   0.01851  0.008679   0.06647        54       640: 100% 25/25 [00:28<00:00,  1.14s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.30it/s]\n",
            "                 all         112         511       0.379       0.515       0.352       0.157\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/54       13G   0.03903   0.01779  0.008952   0.06577        68       640: 100% 25/25 [00:29<00:00,  1.20s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.33it/s]\n",
            "                 all         112         511       0.366        0.53       0.345       0.158\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/54       13G   0.03771   0.01843  0.008475   0.06462        63       640: 100% 25/25 [00:33<00:00,  1.35s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "                 all         112         511       0.399       0.524        0.35       0.163\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/54       13G   0.03718   0.01819  0.009349   0.06471        84       640: 100% 25/25 [00:31<00:00,  1.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.29it/s]\n",
            "                 all         112         511       0.367       0.564       0.346       0.154\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/54       13G   0.03534   0.01748  0.008821   0.06164        64       640: 100% 25/25 [00:32<00:00,  1.30s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.35it/s]\n",
            "                 all         112         511       0.363       0.559        0.34       0.167\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/54       13G    0.0354   0.01759  0.008935   0.06193        79       640: 100% 25/25 [00:33<00:00,  1.32s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.46it/s]\n",
            "                 all         112         511       0.343       0.551        0.33       0.156\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/54       13G   0.03595   0.01869  0.008274   0.06291       129       640: 100% 25/25 [00:30<00:00,  1.21s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.42it/s]\n",
            "                 all         112         511       0.386       0.482       0.345       0.165\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/54       13G   0.03529   0.01836  0.008505   0.06215        61       640: 100% 25/25 [00:32<00:00,  1.30s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.38it/s]\n",
            "                 all         112         511       0.419       0.495       0.385       0.166\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/54       13G   0.03652   0.01801  0.009474     0.064       108       640: 100% 25/25 [00:33<00:00,  1.33s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "                 all         112         511       0.406       0.566       0.393       0.183\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/54       13G   0.03714    0.0166   0.00884   0.06258        36       640: 100% 25/25 [00:31<00:00,  1.27s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.45it/s]\n",
            "                 all         112         511       0.408       0.574       0.401       0.195\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/54       13G   0.03469   0.01809   0.00871    0.0615        50       640: 100% 25/25 [00:35<00:00,  1.41s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.34it/s]\n",
            "                 all         112         511       0.358       0.592       0.383       0.189\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/54       13G   0.03336   0.01688  0.007929   0.05817        94       640: 100% 25/25 [00:33<00:00,  1.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "                 all         112         511        0.38       0.582       0.377       0.179\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/54       13G   0.03614     0.018  0.009131   0.06326       131       640: 100% 25/25 [00:33<00:00,  1.35s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.43it/s]\n",
            "                 all         112         511       0.371        0.59       0.368       0.182\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/54       13G   0.03466   0.01782  0.008018   0.06049        81       640: 100% 25/25 [00:31<00:00,  1.24s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.32it/s]\n",
            "                 all         112         511       0.376       0.568       0.367       0.176\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/54       13G   0.03405   0.01793  0.008965   0.06094        53       640: 100% 25/25 [00:30<00:00,  1.22s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.36it/s]\n",
            "                 all         112         511        0.38       0.516       0.373       0.176\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/54       13G   0.03305   0.01683  0.008878   0.05875        80       640: 100% 25/25 [00:33<00:00,  1.33s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.27it/s]\n",
            "                 all         112         511       0.332       0.513       0.342       0.171\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/54       13G   0.03425   0.01831  0.008726   0.06129        51       640: 100% 25/25 [00:30<00:00,  1.24s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.31it/s]\n",
            "                 all         112         511       0.376        0.44       0.339       0.171\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/54       13G   0.03261   0.01861  0.008558   0.05978        47       640: 100% 25/25 [00:30<00:00,  1.24s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.45it/s]\n",
            "                 all         112         511       0.352       0.463       0.338       0.177\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/54       13G   0.03237   0.01811   0.00843   0.05891        75       640: 100% 25/25 [00:32<00:00,  1.32s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.35it/s]\n",
            "                 all         112         511       0.377       0.545       0.381       0.195\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/54       13G   0.03112   0.01813  0.007532   0.05678        29       640: 100% 25/25 [00:33<00:00,  1.32s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.35it/s]\n",
            "                 all         112         511       0.427       0.491       0.387         0.2\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/54       13G   0.02993   0.01672  0.008337   0.05499        52       640: 100% 25/25 [00:37<00:00,  1.50s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.35it/s]\n",
            "                 all         112         511       0.427       0.489       0.384       0.194\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/54       13G   0.03032   0.01739   0.00803   0.05574        76       640: 100% 25/25 [00:32<00:00,  1.31s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.28it/s]\n",
            "                 all         112         511       0.433       0.419       0.377        0.19\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/54       13G   0.02887    0.0171  0.008654   0.05463        61       640: 100% 25/25 [00:31<00:00,  1.26s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.46it/s]\n",
            "                 all         112         511       0.446       0.419       0.375       0.191\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/54       13G   0.02896   0.01763   0.00819   0.05478        22       640: 100% 25/25 [00:31<00:00,  1.25s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.33it/s]\n",
            "                 all         112         511       0.396       0.481       0.381       0.195\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     50/54       13G    0.0272   0.01776  0.008612   0.05358        94       640: 100% 25/25 [00:34<00:00,  1.40s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.28it/s]\n",
            "                 all         112         511       0.431       0.439       0.372       0.196\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     51/54       13G   0.02783   0.01541  0.008843   0.05209        62       640: 100% 25/25 [00:29<00:00,  1.18s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.29it/s]\n",
            "                 all         112         511       0.385       0.474       0.353       0.179\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     52/54       13G   0.02907   0.01705  0.008809   0.05493        69       640: 100% 25/25 [00:30<00:00,  1.21s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.38it/s]\n",
            "                 all         112         511       0.386       0.453       0.332       0.171\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     53/54       13G   0.02795   0.01756  0.007214   0.05272        49       640: 100% 25/25 [00:35<00:00,  1.41s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.26it/s]\n",
            "                 all         112         511       0.382       0.467        0.34       0.175\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     54/54       13G   0.02817   0.01856  0.008797   0.05553       112       640: 100% 25/25 [00:34<00:00,  1.37s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:05<00:00,  1.28s/it]\n",
            "                 all         112         511       0.388       0.413       0.346       0.173\n",
            "         empty_shelf         112         118       0.507       0.576       0.499       0.248\n",
            "              object         112         393       0.269       0.249       0.193      0.0984\n",
            "55 epochs completed in 0.592 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/exp3/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.1 --source /content/yolov7/ProjectDB-2/test/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-8Psf0zkjkG",
        "outputId": "c147f6d5-a366-49e7-abd7-792908d9441a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.1, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/content/yolov7/ProjectDB-2/test/images', update=False, view_img=False, weights=['runs/train/exp/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.9.0+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"detect.py\", line 196, in <module>\n",
            "    detect()\n",
            "  File \"detect.py\", line 34, in detect\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "  File \"/content/yolov7/models/experimental.py\", line 252, in attempt_load\n",
            "    ckpt = torch.load(w, map_location=map_location)  # load\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/train/exp/weights/best.pt'\n"
          ]
        }
      ]
    }
  ]
}