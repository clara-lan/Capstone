{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MZJN0FkKGAP7hxPLB2Fy_G7lOeyJNXJg",
      "authorship_tag": "ABX9TyMhQU5KZYw4kkJy8Ou+iU2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clara-lan/Capstone/blob/svm-rbf-finaldb/CapstoneSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use SVM to detect empty space and pre-process images"
      ],
      "metadata": {
        "id": "J93ZoQDqaIYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step1: Import system and dependancies"
      ],
      "metadata": {
        "id": "Nwzzdw3yaTjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LtTklnf1hEW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog"
      ],
      "metadata": {
        "id": "Qz5dhKUwauId"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import dataset from Roboflow"
      ],
      "metadata": {
        "id": "876UEB-fahHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import feature"
      ],
      "metadata": {
        "id": "DGizEmtn98UI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL"
      ],
      "metadata": {
        "id": "JJOwwmQWCC9y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.fixes import sklearn\n",
        "import tensorflow.python.platform\n",
        "from tensorflow.python.platform import gfile"
      ],
      "metadata": {
        "id": "IpgNXMqw-4Hy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Read method1: Load roboflow dataset from Roboflow\"\"\"\n",
        "rf = Roboflow(api_key=\"cKIuGvQRsLbBvFgxNztc\")\n",
        "project = rf.workspace(\"boxv4iyolov5pytorch\").project(\"test-gwoka\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EN_dFXHkgpV",
        "outputId": "5d1b6812-b072-48e4-e421-9d6142490eed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = project.version(2).download(\"yolov7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYDsUNgohZSP",
        "outputId": "b33550b8-995b-413d-92f1-c03460b2a3a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset Version Zip in test-2 to yolov7pytorch: 100% [36385967 / 36385967] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to test-2 in yolov7pytorch:: 100%|██████████| 1324/1324 [00:01<00:00, 1085.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IisUaoO8hfaV",
        "outputId": "5530e8cd-4a33-45c2-ca4b-a6789dd8389d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step2: Preprocess data"
      ],
      "metadata": {
        "id": "HI6gpfcDapC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Read images from YOLOv7\"\"\"\n",
        "\n",
        "def extract_images_from_yolov7(path,mode):\n",
        "  \"\"\"\n",
        "    Function: extract_images\n",
        "    Input: path - valid image path in tf record\n",
        "           mode - 1 for training, 2 for test\n",
        "    Output: image dict, {key: {image, label}}, key is index, image is the images name, label is the name of label file\n",
        "  \"\"\"\n",
        "  image_labels_dict = {}\n",
        "  images_path = path+\"/images\"\n",
        "  labels_path = path+'/labels'\n",
        "  images = [f for f in os.listdir(images_path)]\n",
        "  labels = [f for f in os.listdir(labels_path)]\n",
        "  images.sort()\n",
        "  labels.sort()\n",
        "  for i in range(len(images)):\n",
        "    image_labels_dict[i] = [images[i], labels[i]]\n",
        "    # print(images[i])\n",
        "    # # print(\"tuple: \",images[i], \"====tuple:\", labels[i])\n",
        "    # return\n",
        "\n",
        "  return image_labels_dict\n",
        "\n",
        "# extract_images_from_yolov7('/content/ProjectDB-2/test',1)"
      ],
      "metadata": {
        "id": "AeInO3ark6ul"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Convert Tensor to image\n",
        "  Show Image\n",
        "\"\"\"\n",
        "def show_image_from_tensor(tensor):\n",
        "    tensor = tensor*255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "        img_arr = PIL.Image.fromarray(tensor)\n",
        "        plt.imshow(img_arr, interpolation='nearest')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "mGTD6oXq-Mok"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_dataset = tf.data.TFRecordDataset('/content/Empty-shelf-detection-15/test/Empty-space.tfrecord')\n",
        "# valid_dataset = tf.data.TFRecordDataset('/content/Empty-shelf-detection-15/valid/Empty-space.tfrecord')\n",
        "train_labels = '/content/ProjectDB-2/train/empty-shelf-space_label_map.pbtxt'\n",
        "# valid_labels = '/content/Empty-shelf-detection-15/valid/Empty-space_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "1CpXZtaDPG9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step3: Train SVM with YOLOv7 object\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GeQM7_yAZniY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\"\"\"Read labels from .txt file\"\"\"\n",
        "def read_labels(filename):\n",
        "  labels = [x.split(' ') for x in open(filename).readlines()]\n",
        "  for label in labels:\n",
        "    label[-1].rstrip()\n",
        "  return labels\n"
      ],
      "metadata": {
        "id": "Ceie-MOraGDo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Train dataset in YOLOv7\"\"\"\n",
        "from google.colab.patches import cv2_imshow\n",
        "from random import randrange\n",
        "def datagen_yolov7(mode):\n",
        "    \"\"\"\n",
        "    Function: datagen_yolov7 \n",
        "    \n",
        "    Input: \n",
        "        mode - 1 denotes train data ; 2 denotes test data\n",
        "    \n",
        "    Output: Train/Test data and labels depending on mode value\n",
        "    \n",
        "    Description: This function computes HOG features for each image in the Dataset/train or Dataset/test folder, \n",
        "                assigns label to the descriptor vector of the image and returns the final train/test data and labels matrices used for feeding the SVM in training phase or predicting the label of test data.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    ind = 0\n",
        "    if mode == 1:\n",
        "        path = '/content/test-2/valid'\n",
        "    elif mode == 2:\n",
        "        path = '/content/test-2/test'\n",
        "    # read image\n",
        "    image_labels_dict = extract_images_from_yolov7(path, mode)\n",
        "    for key in image_labels_dict.keys():\n",
        "        # compute HOG features\n",
        "        img, label = image_labels_dict[key][0], image_labels_dict[key][1]\n",
        "        # print(img)\n",
        "        image = cv2.imread(path+'/images/'+img)\n",
        "        # cv2_imshow(image)\n",
        "        # return\n",
        "        img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img,(128,128))\n",
        "\n",
        "        # print(type(img))\n",
        "        des, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n",
        "        # print(\"des:\",des)\n",
        "        # print(hog_image)\n",
        "        # print(\"des: \", des)\n",
        "        \"\"\"Read labels\"\"\"\n",
        "        # cv2_imshow(hog_image)\n",
        "        # append descriptor and label to train/test data, labels\n",
        "        X.append(des)\n",
        "        # print(des)\n",
        "        label = read_labels(path+'/labels/'+label)\n",
        "        #store only one label, random get label by index\n",
        "        y.append(label[randrange(len(label))])\n",
        "    return X, y\n",
        "\n",
        "# datagen_yolov7(2)"
      ],
      "metadata": {
        "id": "TybcVsqxqhSB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm_with_yolo_object():\n",
        "    # list of training and test files\n",
        "    # call 'datagen' function to get training and testing data & labels\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    Xtrain, ytrain = datagen_yolov7(1)\n",
        "    Xtest, ytest = datagen_yolov7(2)\n",
        "\n",
        "    # print(\"ytrain: \", ytrain)\n",
        "    # convert matrices to numpy array for fast computation\n",
        "    Xtrain_arr = np.array(Xtrain)\n",
        "    # convert labels to 1d array to enabel sklearn\n",
        "    ytrain = [item[0] for item in ytrain]\n",
        "    # print(\"x: \", len(Xtrain))\n",
        "    # print(\"ytrain: \", ytrain)\n",
        "    \n",
        "\n",
        "    Xtest_arr = np.array(Xtest)\n",
        "    ytest = [item[0] for item in ytest]\n",
        "\n",
        "    # training phase: SVM , fit model to training data ------------------------------\n",
        "    clf = svm.SVC(kernel = 'rbf')\n",
        "    clf.fit(Xtrain_arr, ytrain)\n",
        "    # predict labels for test data\n",
        "    ypred = clf.predict(Xtest_arr)\n",
        "    \n",
        "    # compute accuracy\n",
        "    accuracy = accuracy_score(ytest, ypred) * 100\n",
        "    print(\"\\nAccuracy: %.2f\" % accuracy + \"%\")\n",
        "\n",
        "start_time = time.time()\n",
        "train_svm_with_yolo_object()\n",
        "print('Execution time: %.2f' % (time.time() - start_time) + ' seconds\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpod4cUYhTdn",
        "outputId": "3c5e6676-022c-44cf-f569-759744543e19"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 97.76%\n",
            "Execution time: 4.44 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train with Original YOLOv7\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "t01hZ95f3wcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGW7gP6yE_fl",
        "outputId": "0f0d9d6d-9929-4760-aa28-7cea59198e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 998, done.\u001b[K\n",
            "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n",
            "Receiving objects: 100% (998/998), 69.77 MiB | 22.10 MiB/s, done.\n",
            "Resolving deltas: 100% (467/467), done.\n",
            "/content/yolov7/yolov7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.28.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.10.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 34)) (7.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (5.4.8)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4.21.3->-r requirements.txt (line 14)) (1.15.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 34)) (0.18.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 34)) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download COCO starting checkpoint\n",
        "%cd /content/yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YarX9wvDFzB3",
        "outputId": "58b49213-dcbf-44d0-9c1d-7bfe55b01f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "--2022-11-01 00:03:06--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T000306Z&X-Amz-Expires=300&X-Amz-Signature=2f3281b252535daa4324d2d259750361d5281fb6395590db6bd5d2100cd657aa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 00:03:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T000306Z&X-Amz-Expires=300&X-Amz-Signature=2f3281b252535daa4324d2d259750361d5281fb6395590db6bd5d2100cd657aa&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7_training.pt.1’\n",
            "\n",
            "yolov7_training.pt. 100%[===================>]  72.12M  29.8MB/s    in 2.4s    \n",
            "\n",
            "2022-11-01 00:03:09 (29.8 MB/s) - ‘yolov7_training.pt.1’ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "7hYCeteLWEkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision "
      ],
      "metadata": {
        "id": "rB1BO7MEXtFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "NANvpYaQYaGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K05SarInXdUX",
        "outputId": "911fd4b8-e095-4435-a872-1f550e02d627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this cell to begin training\n",
        "%cd /content/yolov7\n",
        "\"\"\"Download dataset in YOLOv7 object\"\"\"\n",
        "yolo_dataset = project.version(2).download(\"yolov7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dx78NluGAN1",
        "outputId": "8ccbd3c7-31c9-4b14-8de1-18de43448cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Downloading Dataset Version Zip in ProjectDB-2 to yolov7pytorch: 100% [41723011 / 41723011] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to ProjectDB-2 in yolov7pytorch:: 100%|██████████| 1144/1144 [00:00<00:00, 1463.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python train.py --batch 16 --epochs 10 --data /content/yolov7/ProjectDB-2/data.yaml --weights 'yolov7_training.pt' --device 0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1Sz7KoOcE3S",
        "outputId": "080081af-70e2-4966-f101-3b20c881c35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.9.0+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='/content/yolov7/ProjectDB-2/data.yaml', device='0', entity=None, epochs=10, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     39550  models.yolo.IDetect                     [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 415 layers, 37201950 parameters, 37201950 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 557/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'ProjectDB-2/train/labels.cache' images and labels... 395 found, 0 missing, 0 empty, 0 corrupted: 100% 395/395 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'ProjectDB-2/valid/labels.cache' images and labels... 112 found, 0 missing, 0 empty, 0 corrupted: 100% 112/112 [00:00<?, ?it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.70, Best Possible Recall (BPR) = 0.9926\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp2\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/9      7.4G   0.07658   0.02057   0.01665    0.1138        45       640: 100% 25/25 [00:56<00:00,  2.28s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:15<00:00,  3.77s/it]\n",
            "                 all         112         511      0.0109       0.102     0.00453    0.000776\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/9     11.6G   0.07259   0.01845   0.01528    0.1063        87       640: 100% 25/25 [00:36<00:00,  1.47s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.11it/s]\n",
            "                 all         112         511       0.025      0.0547      0.0112     0.00211\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/9       13G   0.06812   0.01846   0.01371    0.1003        49       640: 100% 25/25 [00:35<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.00s/it]\n",
            "                 all         112         511      0.0328       0.104      0.0169     0.00351\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       3/9       13G   0.06442   0.01748   0.01311   0.09502        62       640: 100% 25/25 [00:33<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.33it/s]\n",
            "                 all         112         511      0.0372       0.098      0.0213     0.00485\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       4/9       13G   0.06188   0.01821   0.01222    0.0923        49       640: 100% 25/25 [00:32<00:00,  1.30s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.15it/s]\n",
            "                 all         112         511      0.0427       0.136      0.0289     0.00639\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       5/9       13G     0.059   0.02002   0.01123   0.09024        80       640: 100% 25/25 [00:33<00:00,  1.33s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:02<00:00,  1.39it/s]\n",
            "                 all         112         511      0.0395       0.224       0.033     0.00826\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       6/9       13G   0.05764   0.01981   0.01127   0.08873        85       640: 100% 25/25 [00:36<00:00,  1.45s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.22it/s]\n",
            "                 all         112         511       0.549        0.15      0.0365      0.0099\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       7/9       13G   0.05528   0.02021   0.01109   0.08658        71       640: 100% 25/25 [00:35<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.18it/s]\n",
            "                 all         112         511        0.55       0.221      0.0408      0.0131\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       8/9       13G   0.05459   0.02092   0.01059    0.0861       124       640: 100% 25/25 [00:34<00:00,  1.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.22it/s]\n",
            "                 all         112         511       0.559       0.224      0.0499      0.0152\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       9/9       13G   0.05339   0.01918   0.01076   0.08332        50       640: 100% 25/25 [00:35<00:00,  1.40s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:06<00:00,  1.61s/it]\n",
            "                 all         112         511       0.559       0.214      0.0531      0.0176\n",
            "         empty_shelf         112         118           1           0      0.0103     0.00272\n",
            "              object         112         393       0.118       0.427      0.0959      0.0325\n",
            "10 epochs completed in 0.128 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.1 --source /content/yolov7/ProjectDB-2/test/images"
      ],
      "metadata": {
        "id": "E-8Psf0zkjkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8279367-31e7-4d23-8cc2-7753c05521c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.1, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/content/yolov7/ProjectDB-2/test/images', update=False, view_img=False, weights=['runs/train/exp/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.9.0+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 314 layers, 36487166 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "Done. (26.4ms) Inference, (0.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db104_jpg.rf.4cf3f0f34e8e540ee8735da8f610cc73.jpg\n",
            "Done. (26.4ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db108_jpg.rf.dd59c10cf739f33ea957d5acf596195e.jpg\n",
            "Done. (26.4ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db116_jpg.rf.aa04fca3bd37b3add55e9b8a61fabefb.jpg\n",
            "Done. (26.4ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db126_jpg.rf.d8a4edaf5ddf4fa9b23c309b55f29088.jpg\n",
            "Done. (26.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db128_jpg.rf.621ada1800568b8b0c0c4b82998bbe5b.jpg\n",
            "Done. (26.5ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db140_jpg.rf.258d0debcd1829b16090009bc8d5e5b2.jpg\n",
            "Done. (25.0ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db14_jpg.rf.1ab949361cd2d7e50ab8d1e2645d4dd4.jpg\n",
            "Done. (19.4ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db159_jpg.rf.c5c6a12aaf35238571f222867bc84e20.jpg\n",
            "2 objects, Done. (19.3ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db167_jpg.rf.bbcf3528cefc3a5e176526b82f5ab103.jpg\n",
            "Done. (19.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db16_jpg.rf.45d3c24d1b965b672078c5d28d4dda63.jpg\n",
            "Done. (19.4ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db16_jpg.rf.5ba7249522c1fbe73e70ab868eba2cab.jpg\n",
            "Done. (19.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db171_jpg.rf.62bb49a39af3fd3ae4b43f8e1cbce5ef.jpg\n",
            "Done. (16.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db173_jpg.rf.dba53ed91001da233eea6a3f34dca70a.jpg\n",
            "Done. (16.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db179_jpg.rf.a49ccedc223ae8b20c76e4568a944969.jpg\n",
            "Done. (16.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db182_jpg.rf.405a180af145b9ab47b9753341bdd7ba.jpg\n",
            "Done. (16.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db182_jpg.rf.a4f7e3dcae3956c7d72d2c84541ca837.jpg\n",
            "Done. (15.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db184_jpg.rf.c92c2f0b1c7e4fa858e2d2f45e7cd1c5.jpg\n",
            "Done. (15.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db185_jpg.rf.4da031fa926b587c1181b067634af82c.jpg\n",
            "Done. (15.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db187_jpg.rf.8c8c3ac041ff8ea93783a69f1cc23551.jpg\n",
            "Done. (15.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db202_jpg.rf.cfddf26bb4224abe46132c6d3f8cbbc5.jpg\n",
            "Done. (14.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db20_jpg.rf.a52acb1d5d52b561f72055bea88f23d9.jpg\n",
            "Done. (14.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db216_jpg.rf.e116280a494e4063994465f0ee7a2cee.jpg\n",
            "Done. (14.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db225_jpg.rf.003c8b05b63f471f42dc1585efdc80b0.jpg\n",
            "Done. (13.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db233_jpg.rf.6ec84f6f4ad704fd904bfea174390c7e.jpg\n",
            "Done. (14.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db234_jpg.rf.f4d1f0b28c97f27c8fd6b553739afb45.jpg\n",
            "Done. (14.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db235_jpg.rf.1a9c8e6ad4545aff92877d28772a827b.jpg\n",
            "Done. (14.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db235_jpg.rf.3850fac2cbede90096cf6e3f32c2f985.jpg\n",
            "Done. (14.8ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db236_jpg.rf.d403ba3cd24b8d4b3b24591b66955009.jpg\n",
            "Done. (14.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db237_jpg.rf.dd700d6c2873103db7bd194a20abcc90.jpg\n",
            "2 empty_shelfs, Done. (14.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db239_jpg.rf.932ff26ab86b51734890126af8de2079.jpg\n",
            "Done. (14.4ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db23_jpg.rf.6765400bb85345c7764b58abb05302b8.jpg\n",
            "Done. (13.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db258_jpg.rf.86c5288faefb41305d271d5ef7ee03eb.jpg\n",
            "Done. (14.7ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db272_jpg.rf.86c09fd7ae94f24dc99f0c676f1a9abe.jpg\n",
            "Done. (14.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db275_jpg.rf.015afcafd08ee79a45259810341382a4.jpg\n",
            "Done. (14.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db27_jpg.rf.e0db0471df9eefa579924f3d69927efe.jpg\n",
            "Done. (14.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db282_jpg.rf.0ca4ad5cc72b6236764e754fd0763573.jpg\n",
            "Done. (14.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db284_jpg.rf.765f9908435986d6aa9a44c141c44e3b.jpg\n",
            "Done. (14.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db285_jpg.rf.c67f0f5683c31c24b6d1084c2c8f394d.jpg\n",
            "Done. (17.2ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db286_jpg.rf.5528e701388711874f106a406938e928.jpg\n",
            "Done. (14.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db291_jpg.rf.40a4cd12fd1fadb9558c00d14d74e141.jpg\n",
            "Done. (14.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db292_jpg.rf.319f35330b5f0163067f96f5d75a7557.jpg\n",
            "Done. (14.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db293_jpg.rf.4cf31b02d0d3751a67987cb91bc939e0.jpg\n",
            "Done. (13.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db294_jpg.rf.8ea3686f26e66b0c42c1769da0e8a4ed.jpg\n",
            "Done. (14.7ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db296_jpg.rf.b39e96b7c57373665783053f3240163d.jpg\n",
            "Done. (14.2ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db300_jpg.rf.fc96be1c805f4eac4075fb921df66b0a.jpg\n",
            "Done. (14.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db36_jpg.rf.307694df90fc0e12b79d5a2720886a19.jpg\n",
            "Done. (14.3ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db36_jpg.rf.991694928f1099ff8c39e48bb7b4aa8a.jpg\n",
            "Done. (14.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db3_jpg.rf.674fd261973062c28b97ba46c7b23305.jpg\n",
            "Done. (14.7ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db48_jpg.rf.ac56e7f3b080838495a9690ac7eecb8b.jpg\n",
            "Done. (14.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db4_jpg.rf.38684a570e57e3d32823be062f95cb5c.jpg\n",
            "Done. (14.6ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db53_jpg.rf.c77b6894ee9b67cc2ddb60b9fa7d7a21.jpg\n",
            "Done. (14.2ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db57_jpg.rf.f2dfda2b191e0bb716c66971138645ba.jpg\n",
            "Done. (14.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db62_jpg.rf.eb4399435aa8cc4f2000fab7e93e46be.jpg\n",
            "Done. (14.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db78_jpg.rf.73fe442561e7f345f6bc8415b0915851.jpg\n",
            "Done. (13.9ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db82_jpg.rf.bd68b8e1273d93b8c0b36b15042be444.jpg\n",
            "Done. (14.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db83_jpg.rf.0e33e2c8a25674f1b4d8a3a22e2db6a9.jpg\n",
            "Done. (14.3ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db84_jpg.rf.7dd3c1c1acbcad2baf761af1512d7043.jpg\n",
            "Done. (14.0ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db84_jpg.rf.a2983049cedc4a7843cb4d298651cbde.jpg\n",
            "Done. (14.6ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/db98_jpg.rf.94bb95c55aa9b869343db4e1d5fef7ed.jpg\n",
            "Done. (1.846s)\n"
          ]
        }
      ]
    }
  ]
}