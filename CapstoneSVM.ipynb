{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MZJN0FkKGAP7hxPLB2Fy_G7lOeyJNXJg",
      "authorship_tag": "ABX9TyOGQ9zQpHKc4i9CsoAMjRtS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clara-lan/Capstone/blob/main/CapstoneSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use SVM to detect empty space and pre-process images"
      ],
      "metadata": {
        "id": "J93ZoQDqaIYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step1: Import system and dependancies"
      ],
      "metadata": {
        "id": "Nwzzdw3yaTjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5LtTklnf1hEW",
        "outputId": "ea0393f8-ad4b-4dc0-954e-21b7816bac0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.16-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.6.0.66)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.10)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting kiwisolver==1.3.1\n",
            "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from roboflow) (1.15.0)\n",
            "Collecting certifi==2021.5.30\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 56.7 MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 10.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from roboflow) (2.23.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from roboflow) (7.1.2)\n",
            "Collecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 45.6 MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->roboflow) (2.1.1)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=56995679db77c7c3bf13483cadccf18b7d91af1c2db72636f2bdb0ec30eb0f32\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: urllib3, certifi, requests, pyparsing, kiwisolver, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.4\n",
            "    Uninstalling kiwisolver-1.4.4:\n",
            "      Successfully uninstalled kiwisolver-1.4.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 kiwisolver-1.3.1 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.0 roboflow-0.2.16 urllib3-1.26.6 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler",
                  "kiwisolver",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog"
      ],
      "metadata": {
        "id": "Qz5dhKUwauId"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset from Roboflow"
      ],
      "metadata": {
        "id": "876UEB-fahHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.fixes import sklearn\n",
        "import tensorflow.python.platform\n",
        "from tensorflow.python.platform import gfile\n",
        "\"\"\"Read method1: Load roboflow dataset from Roboflow in tfrecord\"\"\"\n",
        "\n",
        "rf = Roboflow(api_key=\"cKIuGvQRsLbBvFgxNztc\")\n",
        "project = rf.workspace(\"myworkspace-nfnwm\").project(\"capstone-nyjby\")\n",
        "dataset = project.version(3).download(\"tfrecord\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpgNXMqw-4Hy",
        "outputId": "f9a76694-5696-4553-d64b-dbfa5562c25a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Capstone-3 to tfrecord: 100% [28790622 / 28790622] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Capstone-3 in tfrecord:: 100%|██████████| 11/11 [00:00<00:00, 23.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_images(path,mode):\n",
        "  \"\"\"\n",
        "    Function: extract_images\n",
        "    Input: path - valid image path in tf record\n",
        "           mode - 1 for training, 2 for test\n",
        "    Output: image dict, {key: {image, label}}, key is index\n",
        "    Description: This function extract images and labels from tfrecord, maps them to corresponding index\n",
        "  \"\"\"\n",
        "  images = {}\n",
        "  # Create a description of the features.\n",
        "  features = {\n",
        "      \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"image/height\": tf.io.FixedLenFeature([], tf.int64),\n",
        "      \"image/object/bbox/xmax\": tf.io.VarLenFeature(tf.float32),\n",
        "      \"image/object/bbox/xmin\": tf.io.VarLenFeature(tf.float32),\n",
        "      \"image/object/bbox/ymax\": tf.io.VarLenFeature(tf.float32),\n",
        "      \"image/object/bbox/ymin\": tf.io.VarLenFeature(tf.float32),\n",
        "      \"image/object/class/label\": tf.io.VarLenFeature(tf.int64),\n",
        "      \"image/object/class/text\": tf.io.VarLenFeature(tf.string),\n",
        "      \"image/width\": tf.io.FixedLenFeature([], tf.int64),\n",
        "  }\n",
        "  size = 0\n",
        "  idx = 0\n",
        "  if mode == 1:\n",
        "    size = 400\n",
        "  elif mode == 2:\n",
        "    size = 100\n",
        "  train_dataset = tf.data.TFRecordDataset(path)\n",
        "  for raw_record in train_dataset.take(size):\n",
        "    sample = tf.io.parse_single_example(raw_record, features)\n",
        "    image = tf.image.decode_image(sample['image/encoded'], dtype=tf.float32) \n",
        "    label = sample['image/object/class/label']\n",
        "    images[idx] = [image, label]\n",
        "    idx+=1\n",
        "  return images\n",
        "# path =  '/content/Capstone-3/train/empty-shelf-space.tfrecord'\n",
        "# extract_images(path, 1)"
      ],
      "metadata": {
        "id": "lOfRNPtyQi9u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step2: Preprocess data"
      ],
      "metadata": {
        "id": "HI6gpfcDapC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_dataset = tf.data.TFRecordDataset('/content/Empty-shelf-detection-15/test/Empty-space.tfrecord')\n",
        "# valid_dataset = tf.data.TFRecordDataset('/content/Empty-shelf-detection-15/valid/Empty-space.tfrecord')\n",
        "train_labels = '/content/Capstone-3/train/empty-shelf-space_label_map.pbtxt'\n",
        "# valid_labels = '/content/Empty-shelf-detection-15/valid/Empty-space_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "1CpXZtaDPG9G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step3: Train SVM\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GeQM7_yAZniY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rnoMapping = {}\n",
        "\n",
        "def datagen(mode):\n",
        "    \"\"\"\n",
        "    Function: datagen \n",
        "    \n",
        "    Input: \n",
        "        mode - 1 denotes train data ; 2 denotes test data\n",
        "    \n",
        "    Output: Train/Test data and labels depending on mode value\n",
        "    \n",
        "    Description: This function computes HOG features for each image in the Dataset/train or Dataset/test folder, assigns label to the descriptor vector of the image and returns the final train/test data and labels matrices used for feeding the SVM in training phase or predicting the label of test data.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    # TODO: remove the dummy index to select y\n",
        "    idx = 0\n",
        "    cnt = 0\n",
        "    if mode == 1:\n",
        "        path = '/content/Capstone-3/train/empty-shelf-space.tfrecord'\n",
        "    elif mode == 2:\n",
        "        path = '/content/Capstone-3/valid/empty-shelf-space.tfrecord'\n",
        "    # read image\n",
        "    images = extract_images(path, mode)\n",
        "    for key in images.keys():\n",
        "        # compute HOG features\n",
        "        img, label = images[key][0], images[key][1]\n",
        "        # print(type(img))\n",
        "        des, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(4, 4), block_norm= 'L2',visualize=True)\n",
        "        # print(\"des: \", des)\n",
        "\n",
        "        \"\"\"Read labels\"\"\"\n",
        "        # if mode == 1:\n",
        "        #     # construct dictionary for roll no. mapping\n",
        "        #   if label not in rnoMapping.keys():\n",
        "        #       rnoMapping[label] = cnt\n",
        "        #       cnt += 1\n",
        "\n",
        "        # append descriptor and label to train/test data, labels\n",
        "        X.append(des)\n",
        "        label = tf.sparse.to_dense(label).numpy().tolist()\n",
        "        y.append(label)\n",
        "    # print(\"X: \",X)\n",
        "        # print(\"y: \", label)\n",
        "    # return data and label\n",
        "    return X, y\n",
        "# datagen(1)\n",
        "# datagen(2)\n"
      ],
      "metadata": {
        "id": "1iD7Wrf-ZuPp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm():\n",
        "    # list of training and test files\n",
        "    # call 'datagen' function to get training and testing data & labels\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    Xtrain, ytrain = datagen(1)\n",
        "    Xtest, ytest = datagen(2)\n",
        "    # print(\"ytrain: \", ytrain)\n",
        "    # convert matrices to numpy array for fast computation\n",
        "    Xtrain = np.array(Xtrain)\n",
        "    # convert labels to 1d array to enabel sklearn\n",
        "    ytrain = [item[0] for item in ytrain]\n",
        "    # print(\"x: \", len(Xtrain))\n",
        "    # print(\"ytrain: \", ytrain)\n",
        "    Xtest = np.array(Xtest)\n",
        "    ytest = [item[0] for item in ytest]\n",
        "\n",
        "    # training phase: SVM , fit model to training data ------------------------------\n",
        "    clf = svm.SVC(kernel = 'linear')\n",
        "    clf.fit(Xtrain, ytrain)\n",
        "    # predict labels for test data\n",
        "    ypred = clf.predict(Xtest)\n",
        "    \n",
        "    # compute accuracy\n",
        "    accuracy = accuracy_score(ytest, ypred) * 100\n",
        "    print(\"\\nAccuracy: %.2f\" % accuracy + \"%\")\n",
        "start_time = time.time()\n",
        "train_svm()\n",
        "print('Execution time: %.2f' % (time.time() - start_time) + ' seconds\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VvYlhGxnFrk",
        "outputId": "53e08fde-4812-4adf-8259-46705cb3ad6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 82.00%\n",
            "Execution time: 84.81 seconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}